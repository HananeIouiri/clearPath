{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary: 129 layers, 3,157,200 parameters, 0 gradients, 8.9 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(129, 3157200, 0, 8.8575488)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a COCO-pretrained YOLOv8n model\n",
    "# that will create a file called yolov8n that we will use later for prediction\n",
    "model = YOLO(\"yolov8n.pt\", \"v8\")\n",
    "\n",
    "# Display model information (optional)\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import cv2\n",
    "import pyttsx3  # This library will be used for voice notifications\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize voice engine\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 150)  # Speed of speech\n",
    "engine.setProperty('volume', 1)  # Volume level (0.0 to 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"utils/cocoObjects.txt\", \"r\")# this file have all coco pre-trained objects we will use those object on bounding boxes\n",
    "# reading the file\n",
    "data = my_file.read()\n",
    "# split when newline ('\\n') is seen\n",
    "class_list = data.split(\"\\n\")\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just random colors for bounding boxes\n",
    "Boxes = []\n",
    "for i in range(len(class_list)):\n",
    "    r = random.randint(0, 255)\n",
    "    g = random.randint(0, 255)\n",
    "    b = random.randint(0, 255)\n",
    "    Boxes.append((b, g, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize video frames to optimise the run\n",
    "frame_wid = 1240\n",
    "frame_hyt = 920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(\"inference/videos/afriq0.MP4\") # this for a video\n",
    "# Ouvrir la caméra\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to announce the distance and object\n",
    "def announce_distance(class_name, distance):\n",
    "    def speak():\n",
    "        # Announce distance ranges\n",
    "        if distance < 1:\n",
    "            engine.say(f\"Warning! A {class_name} is in front of you, less than 1 meter away.\")\n",
    "        elif 1 <= distance < 2:\n",
    "            engine.say(f\"A {class_name} is in front of you, less than 2 meters away.\")\n",
    "        elif 2 <= distance < 3:\n",
    "            engine.say(f\"A {class_name} is in front of you, about 2 to 3 meters away.\")\n",
    "        elif 3 <= distance < 4:\n",
    "            engine.say(f\"A {class_name} is in front of you, about 3 meters away.\")\n",
    "        elif 4 <= distance < 5:\n",
    "            engine.say(f\"A {class_name} is in front of you, about 4 meters away.\")\n",
    "        elif 5 <= distance < 6:\n",
    "            engine.say(f\"A {class_name} is in front of you, about 5 meters away.\")\n",
    "        else:\n",
    "            engine.say(f\"A {class_name} is far away, more than 5 meters.\")\n",
    "\n",
    "        # Run the speech engine\n",
    "        engine.runAndWait()\n",
    "\n",
    "    # Run the speaking function in a separate thread\n",
    "    threading.Thread(target=speak).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real widths of common objects (meters)\n",
    "REAL_WIDTHS = {\n",
    "    \"person\": 0.5 ,   # Average shoulder width of a person\n",
    "    \"car\": 1.8,      # Average width of a car\n",
    "    \"bottle\": 0.07,  # Average width of a bottle\n",
    "    \"cup\": 0.07\n",
    "}\n",
    "\n",
    "# Focal length (calculated using a known object at a fixed distance)\n",
    "FOCAL_LENGTH = 462  # You need to calculate this once using a known object\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"weights/yolov8n.pt\", \"v8\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame. Exiting ...\")\n",
    "        break\n",
    "\n",
    "    overlay = frame.copy()\n",
    "    cv2.putText(overlay, \"Montrez un objet pour détecter...\", (50, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    # Perform object detection using YOLO model\n",
    "    detect_params = model.predict(source=[frame], conf=0.45, save=False)\n",
    "    DP = detect_params[0].numpy()\n",
    "\n",
    "    if len(DP) != 0:\n",
    "        for i in range(len(detect_params[0])):\n",
    "            boxes = detect_params[0].boxes\n",
    "            box = boxes[i]\n",
    "            clsID = int(box.cls.numpy()[0])\n",
    "            conf = round(float(box.conf.numpy()[0]), 3)\n",
    "            bb = box.xyxy.numpy()[0]\n",
    "\n",
    "            class_name = class_list[clsID]\n",
    "\n",
    "            # ===================== CALCUL DISTANCE =====================\n",
    "            x1, y1, x2, y2 = map(int, bb)\n",
    "            object_roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "            gray = cv2.cvtColor(object_roi, cv2.COLOR_BGR2GRAY)\n",
    "            _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            distance_text = \"Distance: ? m\"\n",
    "\n",
    "            if contours:\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "                rect = cv2.minAreaRect(largest_contour)\n",
    "                object_width_pixels = min(rect[1])  # Use the smaller dimension (width)\n",
    "\n",
    "                object_width_real = REAL_WIDTHS.get(class_name, None)\n",
    "\n",
    "                if object_width_real and object_width_pixels > 0:\n",
    "                    # Calculate the distance based on object width in pixels\n",
    "                    distance = (object_width_real * FOCAL_LENGTH) / object_width_pixels\n",
    "                    distance_text = f\"Distance: {round(distance, 2)} m\"\n",
    "\n",
    "                    # Announce the distance for this object\n",
    "                    announce_distance(class_name, distance)\n",
    "\n",
    "            # ===================== DESSINER =====================\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), Boxes[clsID], 3)\n",
    "\n",
    "            # Line 1: Object name + confidence\n",
    "            cv2.putText(frame, f\"{class_name} {conf}%\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "            # Line 2: Distance\n",
    "            cv2.putText(frame, distance_text, (x1, y1 + 25),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow(\"ObjectDetection\", frame if len(DP) != 0 else overlay)\n",
    "\n",
    "    # Quit if 'q' is pressed or window is closed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    if cv2.getWindowProperty(\"ObjectDetection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### the nearest object\n",
    "##### other objects\n",
    "##### Road Sign Detection (https://www.kaggle.com/datasets/andrewmvd/road-sign-detection)\n",
    "##### traffic lights  (https://github.com/daved01/cocoTraffic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (YoloEnv)",
   "language": "python",
   "name": "yoloenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
